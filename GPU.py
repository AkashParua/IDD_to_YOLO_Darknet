# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16qosBXx0M_YFsK-QtqNEvd-xrdLTWH3t
"""

!ls

import torch
import os 
torch.cuda.get_device_name(0)

!unzip Sample.zip

!pip install memory_profiler super_gradients

!pip install super-gradients

!pip install Pillow

import torch
from PIL import Image
import os
from super_gradients.training import models
import time
from memory_profiler import profile
import numpy as np
yolo_nas_l = models.get("yolo_nas_s", pretrained_weights="coco")

!nvidia-smi

model = yolo_nas_l.to("cuda" if torch.cuda.is_available() else "cpu")

def yolonas(src, t):       
    image = Image.open(src)
    resized_image = image.resize((640,640))
    start = time.time()
    out = model.predict(resized_image)
    tt = t + (time.time() - start)
    
    width, height = image.size
    resized_width, resized_height = resized_image.size
    scale_x = width / resized_width
    scale_y = height / resized_height

    prediction_objects = list(out._images_prediction_lst)[0]
    bbox = prediction_objects.prediction.bboxes_xyxy

    int_labels = prediction_objects.prediction.labels.astype(int)
    class_names = prediction_objects.class_names
    nm = [class_names[i] for i in int_labels]

    conf = prediction_objects.prediction.confidence.astype(float)
   
    fname = f'yolo_nas_coco/'+src[13:-4]+'.txt'
    open(fname, 'w').close()
    with open(fname, 'w') as f:
        for i in range(len(bbox)):
            s = str(nm[i])
            #f.write(s.replace(' ','_')+" ")
            if s in {'cat', 'dog', 'cow', 'elephant', 'horse', 'bear', 'sheep', 'bird'}:
                f.write("animal ")
            elif s in {"laptop","mouse","remote","keyboard","cell phone","microwave","oven","toaster","sink",
	                "refrigerator","book","clock","vase","scissors","teddy bear","hair drier","toothbrush",
                    "backpack","umbrella","handbag","tie","suitcase","frisbee","skis",
	                "snowboard","sports ball","kite","baseball bat","baseball glove","skateboard",
	                "surfboard","tennis racket","bottle","wine glass","cup","fork","knife","spoon",
	                "bowl","banana","apple","sandwich","orange","broccoli","carrot","hot dog","pizza",
	                "donut","cake","chair","couch","potted plant","bed","dining table","toilet","tv"}:
                f.write("other ")
            else :
                f.write(s.replace(' ','_')+" ")
            f.write(str((int(conf[i]*100))/100)+" ")
            f.write(str((int(bbox[i][0]*100))/100 * scale_x ) +" ")
            f.write(str((int(bbox[i][1]*100))/100 * scale_y )+" ")
            f.write(str((int((bbox[i][2]-bbox[i][0])*100))/100 * scale_x)+" ")
            f.write(str((int((bbox[i][3]-bbox[i][1])*100))/100 * scale_y))
            if i!=(len(bbox)-1):
                f.write('\n')
    
    return tt

@profile
def func():
  t = 0
  l = len(os.listdir('Sample'))
  for img in os.listdir('Sample'):
    file_path = os.path.join('Sample',img)
    print(file_path)
    t = yolonas(file_path , t)
  print(t)
  print(torch.cuda.is_available())
  print(f'avg time is {t/l}')

func()

!nvidia-smi
!cat /proc/cpuinfo

!pip install ultralytics

from ultralytics import YOLO
import cv2
yv8_time = 0
c =0
def yolov8():
  global yv8_time
  global c
  model = YOLO('yolov8n.pt')
  root = 'Sample'
  for f in os.listdir(root):
   
    f_path = os.path.join(root , f)
    results = model.predict(source = f_path)
    for result in results:
      yv8_time += result.speed['inference']
      c += 1
yolov8()
print("Average Inference Time (for (640,640) : "+str(yv8_time/c)+"ms")

from torchvision import transforms as T
import torchvision
model = torchvision.models.detection.ssd300_vgg16(pretrained = True)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
def ssd():
  infr = 0
  c = 0
  for d in os.listdir('Sample'):
      src = os.path.join('Sample' , d)
      model.eval()
      #print(src)
      
      ig = Image.open(src)
      width, height = ig.size
      ig = ig.resize((640,640))
      resized_width, resized_height = ig.size
      scale_x = width / resized_width
      scale_y = height / resized_height

      
      transform = T.ToTensor()
      img = transform(ig)
      img = img.to(device)

      with torch.no_grad():
          start = time.time()
          pred = model([img])
          infr += time.time()-start
          c+=1

      bboxes, scores, labels = pred[0]["boxes"], pred[0]["scores"], pred[0]["labels"]
      print("Average Inference Time: "+str(infr/c)+"s")
ssd()